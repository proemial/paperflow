
export const specificPapers = [
    {
        id: 'W4386617002',
        title: 'From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting',
        abstract: "Selecting the 'right' amount of information to include in a summary is a difficult task. A good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a ``Chain of Density'' (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries generated by CoD are more abstractive, exhibit more fusion, and have less of a lead bias than GPT-4 summaries generated by a vanilla prompt. We conduct a human preference study on 100 CNN DailyMail articles and find that that humans prefer GPT-4 summaries that are more dense than those generated by a vanilla prompt and almost as dense as human written summaries. Qualitative analysis supports the notion that there exists a tradeoff between informativeness and readability. 500 annotated CoD summaries, as well as an extra 5,000 unannotated summaries, are freely available on HuggingFace",
        authors: ['Griffin Adams', 'Alexander R. Fabbri', 'Faisal Ladhak', 'Eric Lehman', 'Noémie Elhadad'],
        concepts: ['Automatic summarization', 'Readability', 'Salient'],
        fullPaperUrl: 'https://arxiv.org/pdf/2309.04269',
        link: 'https://paperflow.ai/oa/W4386617002',
        relatedResearch: [
            {
                id: 'W2081830265',
                title: 'Improving readability through extractive summarization for learners with reading difficulties',
                link: 'https://paperflow.ai/oa/W2081830265',
            },
            {
                id: 'W4300055207',
                title: 'DialogSum Challenge: Results of the Dialogue Summarization Shared Task',
                link: 'https://paperflow.ai/oa/W4300055207',
            },
            {
                id: 'W2093597205',
                title: 'A new graph based text segmentation using Wikipedia for automatic text summarization',
                link: 'https://paperflow.ai/oa/W2093597205',
            }
        ]
    },{
        id: 'W4221143046',
        title: 'Chain-of-thought prompting elicits reasoning in large language models',
        abstract: "We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.",
        authors: ['Jason Wei', 'Xuezhi Wang', 'Dale Schuurmans', 'Maarten Bosma', 'Brian Ichter', 'Fei Xia', 'Ed Chi', 'Quoc Le', 'Denny Zhou'],
        concepts: ['Benchmark (surveying)', 'Language model', 'Chain (unit)', 'Commonsense reasoning', 'Word (group theory)', 'Simple (philosophy)', 'Range (aeronautics)'],
        fullPaperUrl: 'http://arxiv.org/pdf/2201.11903',
        link: 'https://paperflow.ai/oa/W4221143046',
        relatedResearch: [
            {
                id: 'W3107474891',
                title: 'Language Model Pre-training Method in Machine Translation Based on Named Entity Recognition',
                link: 'https://paperflow.ai/oa/W3107474891',
            },
            {
                id: 'W2044223291',
                title: 'A dynamic language model based on individual word domains',
                link: 'https://paperflow.ai/oa/W2044223291',
            },
            {
                id: 'W1508636238',
                title: 'An Approach to Acquire Word Translations from Non-parallel Texts',
                link: 'https://paperflow.ai/oa/W1508636238',
            }
        ]
    },{
        id: 'W4387968108',
        title: 'Chain of Propagation Prompting for Node Classification',
        abstract: "Graph Neural Networks (GNN) are an effective technique for node classification, but their performance is easily affected by the quality of the primitive graph and the limited receptive field of message passing. In this paper, we propose a new self-attention method, namely Chain of Propagation Prompting (CPP), to address the above issues as well as reduce dependence on label information when employing self-attention for node classification. To do this, we apply the self-attention framework to reduce the impact of a low-quality graph and to obtain a maximal receptive field for the message passing. We also design a simple pattern of message-passing as the prompt to make self-attention capture complex patterns and reduce the dependence on label information. Comprehensive experimental results on real graph datasets demonstrate that CPP outperforms all relevant comparison methods.",
        authors: ['Yonghua Zhu', 'Zhenyun Deng', 'Robert Amor', 'Michael Witbrock'],
        concepts: ['Message passing', 'Graph', 'Node (physics)', 'Attention network', 'Receptive field', 'Artificial neural network'],
        fullPaperUrl: 'https://dl.acm.org/doi/pdf/10.1145/3581783.3612431',
        link: 'https://paperflow.ai/oa/W4387968108',
        relatedResearch: [
            {
                id: 'W2911286998',
                title: 'Heterogeneous Graph Attention Network',
                link: 'https://paperflow.ai/oa/W2911286998',
            },
            {
                id: 'W2971323980',
                title: 'Graph Neural Networks for Modelling Traffic Participant Interaction',
                link: 'https://paperflow.ai/oa/W2971323980',
            },
            {
                id: 'W2997992893',
                title: 'Fast and Deep Graph Neural Networks',
                link: 'https://paperflow.ai/oa/W2997992893',
            }
        ]
    }
];

export const recentPapers = [
    {
        id: 'W4323637194',
        title: 'Time-Varying Correlation for Noncentered Nonstationary Time Series: Simultaneous Inference and Visualization',
        abstract: "We consider simultaneous inference of the time-varying correlation as a function of time between two nonstationary time series when their trend functions are unknown. Unlike the stationary setting where the effect of precentering using the sample mean is trivially negligible, in the nonstationary setting it is difficult to quantify the impact from precentering using nonparametric trend function estimators. This is mainly due to the trend estimators being time-varying across different time points, which makes it difficult to quantify their cumulative interaction with the error process in the time series setting. We propose to fix this unpleasant issue by using a centering scheme that, instead of aligning with the time point at which the data is observed, aligns with the time point at which the local correlation estimation is performed. We show that this new centering scheme can lead to simultaneous confidence bands with a solid theoretical guarantee for the time-varying correlation between two nonstationary time series when their trend functions are unknown. Numerical examples including a real data analysis are provided to illustrate the proposed method.",
        authors: ['Ting Zhang', 'Yu Shao'],
        concepts: ['Inference', 'Series (stratigraphy)', 'Visualization', 'Time series', 'Correlation'],
        fullPaperUrl: 'https://doi.org/10.5705/ss.202022.0244',
        link: 'https://paperflow.ai/oa/W4323637194',
        relatedResearch: [
            {
                id: 'W1482297635',
                title: 'Estimating Cointegrating Relationships When There Is Uncertainty About The Time Series Properties of',
                link: 'https://paperflow.ai/oa/W1482297635',
            },
            {
                id: 'W2245125350',
                title: 'Inference on the Correlation between Permanent and Transitory Shocks for Unidentified Unobserved Components Models',
                link: 'https://paperflow.ai/oa/W2245125350',
            },
            {
                id: 'W2140339747',
                title: 'Segmented Regressions and Causality (with applications to macroeconomic time series)',
                link: 'https://paperflow.ai/oa/W2140339747',
            }
        ]
    },{
        id: 'w4377819386',
        title: 'Identifying the Most Appropriate Order for Categorical Responses',
        abstract: "Categorical responses arise naturally from various scientific disciplines. Under many circumstances, there is no predetermined order for the response categories and the response has to be modeled as nominal. In this paper we regard the order of response categories as part of the statistical model and show that the true order when it exists can be selected using likelihood-based model selection criteria. For predictive purposes, a statistical model with a chosen order may perform better than models based on nominal responses even if a true order does not exist. For multinomial logistic models widely used for categorical responses, we show the existence of theoretically equivalent orders that are indistinguishable based on likelihood criteria and discover the connections between their maximum likelihood estimators. We use simulation studies and real data analysis to confirm the needs and benefits of choosing the most appropriate order for categorical responses.",
        authors: ['Tianmeng Wang', 'Jie Yang '],
        concepts: ['Categorical variable', 'Order (exchange)'],
        fullPaperUrl: 'https://www3.stat.sinica.edu.tw/ss_newpaper/SS-2022-0322_na.pdf',
        link: 'https://paperflow.ai/oa/w4377819386',
        relatedResearch: [
            {
                id: 'W1963658586',
                title: 'The categorical abstract machine',
                link: 'https://paperflow.ai/oa/W1963658586',
            },
            {
                id: 'W2980926717',
                title: 'Order dense essentiality and behavior of order dense injectivity',
                link: 'https://paperflow.ai/oa/W2980926717',
            },
            {
                id: 'W4200035280',
                title: 'Behavioral model of business change management in relation to building competitiveness in market economy conditions',
                link: 'https://paperflow.ai/oa/W4200035280',
            }
        ]
    },{
        id: 'w4381059439',
        title: 'Reinforcement Learning via Nonparametric Smoothing in a Continuous-Time Stochastic Setting with Noisy Data',
        abstract: "Reinforcement learning was developed mainly for discrete-time Markov decision processes. This paper establishes a novel learning approach based on temporal-difference and nonparametric smoothing to solve reinforcement learning problems in a continuous-time setting with noisy data, where the true model to learn is governed by an ordinary differential equation, and data samples are generated from a stochastic differential equation that is considered as a noisy version of the ordinary differential equation. Continuous-time temporal-difference learning developed for deterministic models is unstable and in fact diverges when applied to data generated from stochastic models. Furthermore, because there are measurement errors or noises in the observed data, a new reinforcement learning framework is needed to handle the learning problems with noisy data. We show that the proposed learning approach has a robust performance for learning deterministic functions based on noisy data generated from stochastic models governed by stochastic differential equations. An asymptotic theory is established for the proposed approach, and a numerical study is carried out to solve a pendulum reinforcement learning problem and check the finite sample performance of the proposed method.",
        authors: ['Chenyang Jiang', 'Bowen Hu', 'Yazhen Wang', 'Shang Wu'],
        concepts: ['Reinforcement learning', 'Nonparametric statistics', 'Smoothing', 'Reinforcement'],
        fullPaperUrl: 'https://www3.stat.sinica.edu.tw/ss_newpaper/SS-2022-0407_na.pdf',
        link: 'https://paperflow.ai/oa/w4381059439',
        relatedResearch: [
            {
                id: 'W4319083788',
                title: 'An Overview of Machine Learning, Deep Learning, and Reinforcement Learning-Based Techniques in Quantitative Finance: Recent Progress and Challenges',
                link: 'https://paperflow.ai/oa/W4319083788',
            },
            {
                id: 'W3022038857',
                title: 'Introducing Self-Learning into Robotic Arm Using Deep Reinforcement Learning',
                link: 'https://paperflow.ai/oa/W3022038857',
            },
            {
                id: 'W3088315509',
                title: 'Intelligent handover decision scheme using double deep reinforcement learning',
                link: 'https://paperflow.ai/oa/W3088315509',
            }
        ]
    }
];



// const result = {
//     papers: [{
//         link: 'https://proem.ai/arxiv/2311.05513',
//         name: 'Positive emotions correlate with better academic performance, showing emotions play a key role in student achievement.',
//         summary: 'This study investigated the use of various indicators, including performance, behavior, and emotions, to identify students struggling with their learning. By analyzing data from students\' interactions with a Learning Management System and their facial expressions captured by webcams, the researchers found a correlation between positive emotions and improved academic outcomes. These findings suggest that emotions play a significant role in distinguishing between high-achieving and low-achieving students.',
//         suggestedQuestions: [
//             'What is the purpose of using a "Chain of Density" prompt in the GPT-4 summarization process?',
//             'How do the summaries generated by the "Chain of Density" prompt compare to those generated by a vanilla prompt?',
//             'What do the results of the human preference study suggest about the density of GPT-4 summaries?'
//         ],
//         metadata: {
//             id: 'W4386617002',
//             title: 'From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting',
//             abstract: "Selecting the ``right'' amount of information to include in a summary is a difficult task. A good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a ``Chain of Density'' (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries generated by CoD are more abstractive, exhibit more fusion, and have less of a lead bias than GPT-4 summaries generated by a vanilla prompt. We conduct a human preference study on 100 CNN DailyMail articles and find that that humans prefer GPT-4 summaries that are more dense than those generated by a vanilla prompt and almost as dense as human written summaries. Qualitative analysis supports the notion that there exists a tradeoff between informativeness and readability. 500 annotated CoD summaries, as well as an extra 5,000 unannotated summaries, are freely available on HuggingFace",
//             authors: ['Griffin Adams', 'Alexander R. Fabbri', 'Faisal Ladhak', 'Eric Lehman', 'Noémie Elhadad'],
//             concepts: ['Automatic summarization', 'Readability', 'Salient'],
//             fullPaperUrl: 'https://arxiv.org/pdf/2309.04269',
//             relatedResearch: [
//                 {
//                     id: 'W2081830265',
//                     title: 'Improving readability through extractive summarization for learners with reading difficulties',
//                     link: 'https://paperflow.ai/oa/W2081830265',
//                 },
//                 {
//                     id: 'W4300055207',
//                     title: 'DialogSum Challenge: Results of the Dialogue Summarization Shared Task',
//                     link: 'https://paperflow.ai/oa/W4300055207',
//                 },
//                 {
//                     id: 'W2093597205',
//                     title: 'A new graph based text segmentation using Wikipedia for automatic text summarization',
//                     link: 'https://paperflow.ai/oa/W2093597205',
//                 }
//             ]
//         }
//     },{
//         link: 'https://paperflow.ai/arxiv/2311.05114',
//         title: 'Automated prompt refinement in chatbots enhances interaction by reducing mental demands and improving performance and social connections.',
//         summary: 'A system called PromptMind has been developed to improve conversations between humans and chatbots. It generates relevant suggestions for what to say next, making conversations smoother and reducing mental effort. Testing the system showed that using PromptMind led to better performance and stronger social connections between users and chatbots. Overall, PromptMind improves the way we interact with chatbots by helping us exchange information more easily.',
//     },{
//         link: 'https://paperflow.ai/arxiv/2311.05373',
//         title: 'Developing prompt literacy is crucial in the AI era as it enhances vocabulary learning strategies and problem-solving skills.',
//         summary: 'In this research, it was found that language learners can develop a new skill called "prompt literacy" in the era of generative AI. Prompt literacy refers to the ability to create specific instructions, understand AI-generated outputs, and refine prompts to achieve desired results. Through an AI-powered project, 30 English learners created artwork representing the meanings of English words by drafting and improving prompts in generative AI tools. The participants reported improved vocabulary learning strategies and recognized the importance of prompt literacy for communication, problem-solving, and career development. This study highlights that prompt literacy is an essential skill in the AI era.',
//     },{
//         link: 'https://paperflow.ai/arxiv/2311.05590',
//         title: 'Conversational AI improves visualizations, but struggles with progressive refinements. AI Threads helps analysts manage conversations effectively.',
//         summary: 'Using advanced language models (AI) capable of generating text, researchers explored their potential to assist in data visualization. They found that these models have limitations when it comes to refining visualizations. To address this, they developed a multi-threaded chatbot called AI Threads, which allows analysts to better manage conversations and improve the effectiveness of visual outputs. Through user studies and interviews, the researchers confirmed that AI Threads is a useful tool for analysts. Additionally, they demonstrated that AI Threads can work with datasets that the language model was not specifically trained on. This study highlights the possibilities and challenges of using language models for data analysis and suggests avenues for further research.',
//     },{
//         link: 'https://paperflow.ai/arxiv/2311.05487',
//         title: 'Reliable news sources dominate information landscape, but unreliable content persists, revealing challenges in combating misinformation.',
//         summary: 'The study analyzed Twitter activity in four European countries and found that while most people rely on reliable news sources, there is still some unreliable content being consumed. Only a small percentage of users engage with questionable information. Interestingly, there are very few people who consume a mix of reliable and questionable news, acting as a bridge between the two. The research also identified differences in the audience overlap of news sources between countries, which could help policymakers and scholars develop better strategies to combat misinformation.',
//     }],
//     followUps: [
//         "What's the key takeaway from paper 3?",
//         "Is any of them related to LLMs?",
//         "Is any of them related to LLMs?"
//     ]
// }
